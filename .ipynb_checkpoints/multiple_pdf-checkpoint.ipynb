{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1455b7a-0ed7-4b78-9722-726544f6559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83c6ea32-bfa6-44d3-9ede-9872b4b5db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GEMINI_API_KEY\"]=\"AIzaSyBBF0rGyp8y0pJdfOnykCElApzNWJGuB7k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3207c479-455c-4395-8e89-d556570dc652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfc0590b-1bc6-45b6-99d1-799f8f234350",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    def __call__(self, input:Documents)-> Embeddings:\n",
    "        gemini_api_key=os.getenv(\"GEMINI_API_KEY\")\n",
    "        if not gemini_api_key:\n",
    "            raise ValueError(\"API KEY NOT PROVIDED\")\n",
    "        genai.configure(api_key=gemini_api_key)\n",
    "        model = \"models/embedding-001\"\n",
    "        title = \"Custom query\"\n",
    "        return genai.embed_content(model = model,\n",
    "                                  content = input,\n",
    "                                  task_type=\"retrieval_document\",\n",
    "                                  title=title)[\"embedding\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1cccba-10cf-4338-9566-2d3722d99c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from typing import List\n",
    "def create_chroma_db(documents:List, path:str, name:str):\n",
    "\n",
    "    chroma_client = chromadb.PersistentClient(path=path)\n",
    "    db = chroma_client.create_collection(name=name,embedding_function=GeminiEmbeddingFunction())\n",
    "    for i, d in enumerate(documents):\n",
    "        db.add(documents=d, ids=str(i))\n",
    "    return db,name\n",
    "\n",
    "db, name=create_chroma_db(documents=chunked_text,\n",
    "                          path =\"chroma_db/\",\n",
    "                          name=\"llm_rag_fellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91e73647-76f9-4223-8530-6e72e2e25948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chunk_persist_pdf() -> Chroma:\n",
    "    pdf_folder_path = \"C:\\\\Users\\\\ASUS\\\\Desktop\\\\Python Deep Learning\\\\data\\\\articles\\\\\"\n",
    "    documents = []\n",
    "    for file in os.listdir(pdf_folder_path):\n",
    "        if file.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(pdf_folder_path,file)\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            documents.extend(loader.load())\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000,chunk_overlap=10)\n",
    "    chunked_documents = text_splitter.split_documents(documents)\n",
    "    \n",
    "    client = chromadb.Client()\n",
    "    if client.list_collections():\n",
    "        consent_collection = client.create_collection(\"rag_llm_fellow\")\n",
    "    else:\n",
    "        print(\"Collection already exists\")\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=chunked_documents,\n",
    "        embedding=GeminiEmbeddingFunction(),\n",
    "        persist_directory=\"C:\\\\Users\\\\ASUS\\\\Desktop\\\\Python Deep Learning\\\\data\\\\articles\\\\chroma_db\\\\\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    vectordb.persist()\n",
    "    return vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cd97f6e-e120-419d-914f-8e55d592d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chunk_persist_pdf() -> Chroma:\n",
    "    pdf_folder_path = \"C:\\\\Users\\\\ASUS\\\\Desktop\\\\Python Deep Learning\\\\data\\\\articles\\\\\"\n",
    "    documents = []\n",
    "    for file in os.listdir(pdf_folder_path):\n",
    "        if file.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(pdf_folder_path, file)\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            documents.extend(loader.load())\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
    "    chunked_documents = text_splitter.split_documents(documents)\n",
    "    return chunked_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c53dc99d-b138-4c76-b04b-ffd882e6b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_documents = load_chunk_persist_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6af0854-76b0-4c0f-a4b4-e290fa59599d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(chunked_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca47ce34-296b-40b0-a397-4fb13be0c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_store(text_chunks):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\") # google embeddings\n",
    "    vector_store = FAISS.from_texts(text_chunks,embeddings) # use the embedding object on the splitted text of pdf docs\n",
    "    vector_store.save_local(\"faiss_index\") # save the embeddings in local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbc22e5-73d7-4f51-9b9d-01bb39c519ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e035c00-6561-425a-af61-bf30e81aa1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_vector_store(text_chunks):\n",
    "    # Google embeddings modelini yükle\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "    # Chroma kullanarak metin parçalarını yükle\n",
    "    chroma_db = Chroma.from_texts(text_chunks, embeddings)\n",
    "\n",
    "    # Vektör deposunu yerel olarak kaydet\n",
    "    chroma_db.save_local(\"//chroma_db//rag_test\")\n",
    "\n",
    "    return chroma_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fedbf7e6-6603-4a48-bfac-1782a0c5209e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for GoogleGenerativeAIEmbeddings\n__root__\n  Did not find google_api_key, please add an environment variable `GOOGLE_API_KEY` which contains it, or pass `google_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_vector_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunked_documents\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[42], line 3\u001b[0m, in \u001b[0;36mget_vector_store\u001b[1;34m(text_chunks)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vector_store\u001b[39m(text_chunks):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Google embeddings modelini yükle\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mGoogleGenerativeAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/embedding-001\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Chroma kullanarak metin parçalarını yükle\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     chroma_db \u001b[38;5;241m=\u001b[39m Chroma\u001b[38;5;241m.\u001b[39mfrom_texts(text_chunks, embeddings)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\OpenAI\\lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for GoogleGenerativeAIEmbeddings\n__root__\n  Did not find google_api_key, please add an environment variable `GOOGLE_API_KEY` which contains it, or pass `google_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "get_vector_store(chunked_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edfb0f0-14e4-4255-90b8-dd4c5bcafab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a84f65-80cc-4db4-9e5b-68852a7dd54c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c809d574-fc28-4423-9d0d-6ab881249ccd",
   "metadata": {},
   "source": [
    "# multiple pdf until chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78a6181c-65b4-4822-8b5a-025923c8f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader #library to read pdf files\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter#library to split pdf files\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45556428-6408-4d7f-aef1-45c70a301199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings #to embed the text\n",
    "import google.generativeai as genai\n",
    "\n",
    "from langchain.vectorstores import FAISS #for vector embeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI #\n",
    "from langchain.chains.question_answering import load_qa_chain #to chain the prompts\n",
    "from langchain.prompts import PromptTemplate #to create prompt templates\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d844a223-249f-4f5e-9eda-6392fe0857f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_text(pdf_docs):\n",
    "    text = \"\"\n",
    "    # iterate over all pdf files uploaded\n",
    "    for pdf in pdf_docs:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        # iterate over all pages in a pdf\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6158e596-f4fb-435a-a12a-b9aafa46b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_text(pdf_docs):\n",
    "    text = \"\"\n",
    "    # iterate over all pdf files uploaded\n",
    "    for pdf in pdf_docs:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        # iterate over all pages in a pdf\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb8c17-e988-4f75-9727-212915f06489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc28019-ef3d-4c3e-ba82-1313b92a7c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "435ff1bf-0e55-41e4-a5df-2ab628acbf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_text(pdf_folder_path):\n",
    "    text = \"\"\n",
    "    # iterate over all pdf files in the specified folder path\n",
    "    for file_name in os.listdir(pdf_folder_path):\n",
    "        if file_name.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(pdf_folder_path, file_name)\n",
    "            pdf_reader = PdfReader(pdf_path)\n",
    "            # iterate over all pages in a pdf\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fb214a-e55a-463e-888c-a96570bb8eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF dosyalarının bulunduğu dizin yolu\n",
    "pdf_folder_path = \"C:\\\\Users\\\\ASUS\\\\Desktop\\\\Python Deep Learning\\\\data\\\\articles\\\\\"\n",
    "\n",
    "# PDF dosyalarını oku ve içeriklerini birleştir\n",
    "pdf_text = get_pdf_text(pdf_folder_path)\n",
    "\n",
    "# Elde edilen metni yazdır\n",
    "print(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80e2d93-72b7-41e8-a5f7-f58ba52a4081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
